<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Mingkai Chen</title>

  <meta name="author" content="Mingkai Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Mingkai Chen</name>
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:mxceec@rit.edu">Email</a> &nbsp/&nbsp
                    <a href="https://files.mingkai.me/pdfs/resume.pdf">CV</a> &nbsp/&nbsp
                    <!-- <a href="https://files.mingkai.me/txts/bio.txt">Bio</a> &nbsp/&nbsp -->
                    <a href="https://scholar.google.com/citations?user=Oi9uz1kAAAAJ">Google Scholar</a> &nbsp/&nbsp
                    <a href="https://github.com/MingkaiChen">Github</a>
                    <!-- <a href="https://www.mingkai.me/projects.html">Projects</a> -->
                  </p>
                  <p>
                    I am currently a first-year doctoral student at <a href="https://www.rit.edu/engineering/computerengineering">Department of Computer Engineering</a>, <a href="https://www.rit.edu">Rochester Institute of Technology</a>.
                    Prior to that, I graduated from <a href="https://www.stonybrook.edu/">Stony Brook University</a> with Bachelor of Science in <a href="https://cs.stonybrook.edu/">Computer Science</a>.
                  </p>
                  <p>
                    Under the supervision of <a href="https://dongfang-liu.github.io/">Prof. Dongfang Liu</a>, I am actively conducting research in the field of Artificial Inteligence. 
                    My research interests cover a wide range of topics in this field, such as AI for Science, Large Language Models, and Multi-modal Models, among others.
                  </p>
                  <!-- <p style="color:red">
                    <em> I'm a highly self-motivated student and am now looking for a Ph.D. position starting in Fall 2024.
                      Please feel free to email me if my experience might be a good fit for your lab. </em>
                  </p> -->
                </td>
                <td>
                  <img style="width:100%;max-width:100%" alt="profile photo"
                    src="https://imagedelivery.net/P2sL66XTJLlL8ewcfAdVqQ/49264f24-a5c7-4b9d-1a27-1dcd4eef7b00/avatar" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    My research interests lie in the field of Artificial Inteligence. The most of my current works focused on
                    <em style="color:red"> AI for Science </em>, <em style="color:red"> Large Language Models </em> and <em
                      style="color:red"> Multi-modal Models </em>.
                  </p>
                </td>
              </tr>
              <!-- <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <papertitle>Object Detection of Human-hold Handguns in Surveillance Images
                  </papertitle>
                  <br>
                  Under the supervision of Prof. Haibin Ling.
                  <br>
                  <em>Ongoing research</em>&nbsp;
                  <br>
                  Thanks to the work of <a href="https://arxiv.org/abs/2303.10703">CCTV-Gun</a>, we were able to conduct research in the important scenario of handguns detection in surveillance images. We aim to enhance the performance of handguns detection by studying the Human-Object Interactions between the hundgun and the holder.
                </td>
              </tr> -->
              <!-- <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <papertitle>Large and Foundamental Model to Address Various DNA and RNA Related Tasks
                  </papertitle>
                  <br>
                  With collaborators from University of Rochester, Harvard University, and City University of Hong Kong.
                  <br>
                  <em>Ongoing research</em>&nbsp;
                  <br>
                  We aim to design a large and foundamental model using extensive data for DNA and RNA mutations, in order to address various DNA and RNA related tasks.
                </td>
              </tr> -->
              <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <papertitle><a href="https://arxiv.org/abs/2407.11098">Inertial Confinement Fusion Forecasting via LLMs</a>
                  </papertitle>
                  <br>
                  <a href="https://www.mingkai.me"><strong>Mingkai Chen</strong></a>, 
                  Taowen Wang, 
                  <a href="https://jamesliang819.github.io/">James Chenhao Liang</a>, 
                  <a href="https://scholar.google.com/citations?user=3vP25GAAAAAJ">Chuan Liu</a>, 
                  <a href="https://scholar.google.com/citations?user=B6At13MAAAAJ">Chunshu Wu</a>, 
                  <a href="https://wqfcr.github.io/">Qifan Wang</a>, 
                  <a href="http://www.stat.ucla.edu/~ywu/">Ying Nian Wu</a>, 
                  <a href="https://www.hajim.rochester.edu/ece/sites/michaelhuang/">Michael Huang</a>, 
                  <a href="https://scholar.google.com/citations?user=et5egTYAAAAJ">Chuang Ren</a>, 
                  <a href="https://www.angliphd.com/">Ang Li</a>, 
                  <a href="https://www.tonytgeng.com/">Tong Geng</a>, 
                  <a href="https://dongfang-liu.github.io/">Dongfang Liu</a>
                  <br>
                  <em>arXiv, Under review by NeurIPS 2024</em>&nbsp;
                  <br>
                  We developed Fusion-LLM, a novel integration of Large Language Models (LLMs) with reservoir computing paradigms, tailored for Inertial Confinement Fusion (ICF). The approach includes an LLM-anchored Reservoir for accurate forecasting of hot electron dynamics, Signal-Digesting Channels for detailed temporal and spatial analysis of laser intensity, and a Confidence Scanner to quantify prediction confidence. Demonstrated superior performance in predicting Hard X-ray (HXR) energies, achieving state-of-the-art results. Introduced Fusion4AI, the first ICF benchmark based on physical experiments, to foster advancements in AI-driven plasma physics research.
                </td>
              </tr>
              <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <papertitle><a href="https://arxiv.org/abs/2401.02582">CoCoT: Contrastive Chain-of-Thought Prompting for Large Multimodal Models with Multiple Image Inputs</a>
                  </papertitle>
                  <br>
                  <a href="https://dwan.ch">Daoan Zhang</a>*,
                  <a href="https://junming-yang.github.io/">Junming Yang</a>*,
                  <a href="https://brucelyu17.github.io/">Hanjia Lyu</a>*,
                  <a href="https://scholar.google.com/citations?user=cZu17HsAAAAJ">Zijian Jin</a>,
                  <a href="https://www.cs.rochester.edu/u/yyao39/">Yuan Yao</a>,
                  <a href="https://www.mingkai.me"><strong>Mingkai Chen</strong></a>,
                  <a href="https://www.cs.rochester.edu/u/jluo/">Jiebo Luo</a>
                  <br>
                  <em>ICPR 2024</em>&nbsp;
                  <br>
                  We investigated Large Multimodal Models' (LMMs) ability to process multiple image inputs, focusing on fine-grained perception and information blending. Our research involved image-to-image matching and multi-image-to-text matching assessments, using models like GPT-4V and Gemini. We developed a Contrastive Chain-of-Thought (CoCoT) prompting method to improve LMMs' multi-image understanding, significantly enhancing model performance in our evaluations.
                </td>
              </tr>
              <tr onmouseout="motionblur_stop()" onmouseover="motionblur_start()">
                <td
                  style="padding-top:0px;padding-bottom:20px;padding-left:20px;padding-right:20px;width:75%;vertical-align:middle">
                  <papertitle><a href="https://arxiv.org/abs/2302.02350">Aggregation of Disentanglement: Reconsidering Domain Variations in Domain Generalization</a>
                  </papertitle>
                  <br>
                  <a href="https://dwan.ch">Daoan Zhang</a>*,
                  <a href="https://www.mingkai.me"><strong>Mingkai Chen</strong></a>*,
                  <a href="https://scholar.google.com/citations?user=H0R4vmMAAAAJ">Chenming Li</a>,
                  Lingyun Huang,
                  <a href="https://faculty.sustech.edu.cn/zhangjg/en/">Jianguo Zhang</a>
                  <br>
                  <em>arXiv, Under review by IJCV</em>&nbsp;
                  <br>
                  We proposed a new perspective to utilize class-aware domain variant features in training, and in the
                  inference period, our model effectively maps target domains into the latent space where the known
                  domains lie. We also designed a contrastive learning based paradigm to calculate the weights for
                  unseen domains.
                </td>
              </tr>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <em>* equal contribution.</em>
                </td>
              </tr>
        </td>
      </tr>
    </tbody>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>

    </tbody>
  </table>


  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
        <td>
          <heading>Services</heading>
        </td>
      </tr>
    </tbody>
  </table>
  <table width="100%" align="center" border="0" cellpadding="20">
    <tbody>
      <td style="padding:15px;width:5%;vertical-align:middle">
        <img src="https://files.mingkai.me/imgs/SBU vert_2clr_rgb_300ppi.png" alt="SUSTech" width="50">
      </td>
      <td width="95%" valign="center">
        Student Assistant, Department of Computer Science, Stony Brook University
      </td>
      </tr>


    </tbody>
  </table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr>
        <br>
        <br>
        <br>
        <br>
        <br>
        <td style="padding:0px" align="right">
          <a href="https://jonbarron.info"> credits </a>
          </p>
        </td>
      </tr>
    </tbody>
  </table>
  </td>
  </tr>
  </table>
</body>

</html>
